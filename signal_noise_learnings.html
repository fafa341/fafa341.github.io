<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Signal in the Noise - Learnings | Fabio Fuentes</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
      body {
        background-color: white;
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 14px;
        color: #1f1f1f;
        max-width: 800px;
        margin: 40px auto;
        padding: 20px;
        line-height: 1.6;
      }
      h1 {
        font-size: 28px;
        margin-bottom: 10px;
      }
      h2 {
        font-size: 20px;
        margin-top: 30px;
        margin-bottom: 10px;
      }
      a {
        color: #1772d0;
        text-decoration: none;
      }
      a:hover {
        color: #f09228;
      }
      .back-link {
        margin-bottom: 30px;
      }
    </style>
  </head>
  <body>
    <div class="back-link">
      <a href="index.html">‚Üê Back to main page</a>
    </div>

    <h1>Signal in the Noise: Learnings</h1>
    <p><em>A State-Dependent Local Projection Analysis of News Narratives and the Chilean Business Cycle</em></p>

    <h2>Key Learnings</h2>
    <p>
      Causal inference can be achieved with more specificity. Simpler tools can work better.
    </p>
    <p>
      There's many ways to keep contributing to science with applied ML and NLP. Evaluating different tools and refining them based on research is the way.
    </p>
    <p>
      Essentially predicting individuals is not possible. Other economic agents are different.
    </p>
    <p>
      Maintaining order with folders and files was a must. Documenting every week is needed. Also commenting code is really needed.
    </p>
    <p>
      Learning on demand is what truly drives progress.
    </p>

    <h2>Technical Insights</h2>
    <p>
      LLMs can really leverage your technical work. Usually plan with Gemini Deep research feature and execute with Claude. To avoid hallucinations use Google AI Studio with Gemini as well. Claude was better for understanding HTML and developing scraping, Gemini better at qualitative understanding and performance of tasks.
    </p>

    <h2>Challenges and Solutions</h2>
    <p>
      Scraping old HTML and cleaning data was time consuming and hard. Manipulating LDA to maintain consistency and a solid output was hard. Creating a consistent data pipeline was hard. Developing substantive knowledge about the field over the years was hard (without this, this couldn't have been done).
    </p>

    <h2>Future Work</h2>
    <p>
      To contribute to science I really think evaluating if current ML or LLM techniques can provide a more accurate and time cost benefit analysis over LDA. BERTopic could be evaluated. By accuracy I mean topic manipulation and consistency over time. Also, adding context understanding can help structure narratives in different ways.
    </p>

  </body>
</html>
